{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzYd5tvnwp3e"
      },
      "source": [
        "# 0. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWtT3sIEwZOp",
        "outputId": "f631bfa2-45c0-4d86-8f75-bd643329763a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at drive\n"
          ]
        }
      ],
      "source": [
        "# Mount to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyTIbs9OwzQp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import transforms\n",
        "from torchvision.models import vgg19\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# TPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/MyDrive/SR-ATS'\n",
        "\n",
        "import os\n",
        "os.chdir(folder_path+'/functions')"
      ],
      "metadata": {
        "id": "82h1yRw0rI2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OHhySgR7bxa"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import net_tester\n",
        "import data_loader\n",
        "\n",
        "set14_path = data_loader.un_zip(\"set14\")\n",
        "set5_path  = data_loader.un_zip(\"set5\")\n",
        "bsd_path   = data_loader.un_zip(\"BSD100\")\n",
        "urban_path = data_loader.un_zip(\"urban100\")\n",
        "\n",
        "#net_tester.test_set(set14_path, device, model, save_path=None)\n"
      ],
      "metadata": {
        "id": "5fxZG6nL23XS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "SF6jUEl17foa"
      },
      "outputs": [],
      "source": [
        "import net\n",
        "import importlib\n",
        "importlib.reload(net)\n",
        "\n",
        "# Load Model\n",
        "model_name = \"v3\"\n",
        "model = torch.load(\"../models/save/SR-ATS-3.pth\")\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "torch.save(model, f\"../models/save/model_{model_name}.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBgywPeXPNvb"
      },
      "outputs": [],
      "source": [
        "print(\"[set5]\")\n",
        "net_tester.test_set(set5_path , device, model, save_path=f\"../outputs/{model_name}/s5\")\n",
        "\n",
        "print(\"\\n[set14]\")\n",
        "net_tester.test_set(set14_path, device, model, save_path=f\"../outputs/{model_name}/s14\")\n",
        "\n",
        "print(\"\\n[bsd]\")\n",
        "net_tester.test_set(bsd_path  , device, model, save_path=f\"../outputs/{model_name}/bsd\")\n",
        "\n",
        "print(\"\\n[urban]\")\n",
        "net_tester.test_set(urban_path, device, model, save_path=f\"../outputs/{model_name}/urb\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Images (Fig3)"
      ],
      "metadata": {
        "id": "dcVMqcmhGoY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net_tester.test_set(\"../test/GT\", device, model, save_path=f\"../test/v3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLnmhlISGs1E",
        "outputId": "b02ea841-802f-44e9-9898-26f9e416a0c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/SR-ATS/functions/net_tester.py:16: UserWarning: Inputs have mismatched dtype.  Setting data_range based on image_true.\n",
            "  return metrics.peak_signal_noise_ratio(img1, img2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "psnr: 27.79811691400675, ssim: 0.79680049160359\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def process_images(input_folder, output_folder):\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
        "            img = Image.open(os.path.join(input_folder, filename))\n",
        "            width, height = img.size\n",
        "            img_downsampled = img.resize((width // 4, height // 4), Image.BICUBIC)\n",
        "            img_upscaled = img_downsampled.resize((width, height), Image.BICUBIC)\n",
        "            output_path = os.path.join(output_folder, filename)\n",
        "            img_upscaled.save(output_path)\n",
        "            print(f\"Processed and saved: {output_path}\")\n",
        "\n",
        "input_folder = '../test/GT'\n",
        "output_folder = '../test/bicubic'\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "process_images(input_folder, output_folder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vH_nyj67G8bD",
        "outputId": "ccd2382b-2e95-48a5-ba8a-e2dfd8b84aac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed and saved: ../test/bicubic/bsd040.png\n",
            "Processed and saved: ../test/bicubic/img_019.png\n",
            "Processed and saved: ../test/bicubic/img_021.png\n",
            "Processed and saved: ../test/bicubic/img_028.png\n",
            "Processed and saved: ../test/bicubic/img_067.png\n",
            "Processed and saved: ../test/bicubic/img_100.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization (Fig 4)"
      ],
      "metadata": {
        "id": "G-mGy5ui3H6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0kjYsyX84_r",
        "outputId": "9fc1078d-962b-4a2b-8227-c4bc07173ee0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SR_v3(\n",
            "  (vgg_3): relu_3_4(\n",
            "    (feature_extractor): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (3): ReLU(inplace=True)\n",
            "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (6): ReLU(inplace=True)\n",
            "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (8): ReLU(inplace=True)\n",
            "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (11): ReLU(inplace=True)\n",
            "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (13): ReLU(inplace=True)\n",
            "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (15): ReLU(inplace=True)\n",
            "      (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (17): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (vgg_2): relu_2_2(\n",
            "    (feature_extractor): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (3): ReLU(inplace=True)\n",
            "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (6): ReLU(inplace=True)\n",
            "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (8): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (vgg_1): relu_1_2(\n",
            "    (feature_extractor): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (3): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (p0_1): ConvBlock(\n",
            "    (conv): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=reflect)\n",
            "    (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (p0_2): ConvBlock(\n",
            "    (conv): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=reflect)\n",
            "    (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (p0_3): ConvBlock(\n",
            "    (conv): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=reflect)\n",
            "    (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (p0_4): ConvBlock(\n",
            "    (conv): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=reflect)\n",
            "    (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (d4): DecodeBlock(\n",
            "    (upsample): Upsample(scale_factor=2.0, mode='bicubic')\n",
            "    (c1): ConvBlock(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=reflect)\n",
            "      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (c2): ConvBlock(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=reflect)\n",
            "      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (c3): ConvBlock(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=reflect)\n",
            "      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (c4): ConvBlock(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=reflect)\n",
            "      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (c5): ConvBlock(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=reflect)\n",
            "      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (c6): ConvBlock(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=reflect)\n",
            "      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "  )\n",
            "  (d3): DecodeBlock(\n",
            "    (upsample): Upsample(scale_factor=2.0, mode='bicubic')\n",
            "    (c1): ConvBlock(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=reflect)\n",
            "      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (c2): ConvBlock(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=reflect)\n",
            "      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (c3): ConvBlock(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=reflect)\n",
            "      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (c4): ConvBlock(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=reflect)\n",
            "      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (c5): ConvBlock(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=reflect)\n",
            "      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (c6): ConvBlock(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=reflect)\n",
            "      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "  )\n",
            "  (d2): DecodeBlock(\n",
            "    (upsample): Upsample(scale_factor=2.0, mode='bicubic')\n",
            "    (c1): ConvBlock(\n",
            "      (conv): Conv2d(256, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=reflect)\n",
            "      (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (c2): ConvBlock(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=reflect)\n",
            "      (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (c3): ConvBlock(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=reflect)\n",
            "      (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (c4): ConvBlock(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=reflect)\n",
            "      (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (c5): ConvBlock(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=reflect)\n",
            "      (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (c6): ConvBlock(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=reflect)\n",
            "      (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "  )\n",
            "  (d1): DecodeBlock(\n",
            "    (upsample): Upsample(scale_factor=2.0, mode='bicubic')\n",
            "    (c1): ConvBlock(\n",
            "      (conv): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=reflect)\n",
            "      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (c2): ConvBlock(\n",
            "      (conv): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=reflect)\n",
            "      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (c3): ConvBlock(\n",
            "      (conv): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=reflect)\n",
            "      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (c4): ConvBlock(\n",
            "      (conv): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=reflect)\n",
            "      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (c5): ConvBlock(\n",
            "      (conv): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=reflect)\n",
            "      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (c6): ConvBlock(\n",
            "      (conv): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), padding_mode=reflect)\n",
            "      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "  )\n",
            "  (e1): ConvBlock(\n",
            "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
            "    (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (e2): ConvBlock(\n",
            "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
            "    (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (e3): ConvBlock(\n",
            "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
            "    (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (e4): ConvBlock(\n",
            "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
            "    (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (e5): ConvBlock(\n",
            "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
            "    (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (e6): ConvBlock(\n",
            "    (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
            "    (batchnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (e7): ConvBlock(\n",
            "    (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
            "    (batchnorm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (end): ConvBlock(\n",
            "    (conv): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
            "    (batchnorm): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "\n",
        "image_path = \"../outputs/visualization/bsd040.png\"\n",
        "\n",
        "image = Image.open(image_path)\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "image_tensor = transform(image)\n",
        "\n",
        "import torch.nn.functional as F\n",
        "image_tensor = F.interpolate(image_tensor.unsqueeze(0), scale_factor=0.25, mode='bicubic')\n"
      ],
      "metadata": {
        "id": "ski7Ie1L9mI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">input"
      ],
      "metadata": {
        "id": "fX7b29JkZ_kU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "layer_name = \"inp-feat\"\n",
        "\n",
        "features = []\n",
        "def get_features(module, input, output):\n",
        "    features.append(input[0])\n",
        "\n",
        "layer = model.d3.upsample\n",
        "hook = layer.register_forward_hook(get_features)\n",
        "\n",
        "output = model(image_tensor.to(device))\n",
        "\n",
        "feature_map = features[0]\n",
        "\n",
        "hook.remove()"
      ],
      "metadata": {
        "id": "Iv3BhTY37pid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = f'../outputs/visualization/{layer_name}'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "batch_size, num_channels, height, width = feature_map.shape\n",
        "\n",
        "for i in range(num_channels):\n",
        "    feature = feature_map[0, i].detach().cpu().numpy()\n",
        "\n",
        "    # Normalize to [0, 255] for visualization\n",
        "    feature = (feature - feature.min()) / (feature.max() - feature.min())\n",
        "    feature = (feature * 255).astype('uint8')\n",
        "\n",
        "    img = Image.fromarray(feature)\n",
        "    save_path = os.path.join(save_dir, f'{layer_name}_{i+1}.png')\n",
        "    img.save(save_path)"
      ],
      "metadata": {
        "id": "34Yx8AgB93H_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> output"
      ],
      "metadata": {
        "id": "kVSbm7-laCPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "layer_name = \"out-feat\"\n",
        "\n",
        "features = []\n",
        "def get_features(module, input, output):\n",
        "    features.append(input[0])\n",
        "\n",
        "layer = model.d2.upsample\n",
        "hook = layer.register_forward_hook(get_features)\n",
        "\n",
        "output = model(image_tensor.to(device))\n",
        "\n",
        "feature_map = features[0]\n",
        "\n",
        "hook.remove()"
      ],
      "metadata": {
        "id": "6d1QE-E_aKhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = f'../outputs/visualization/{layer_name}'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "batch_size, num_channels, height, width = feature_map.shape\n",
        "print(feature_map.shape)\n",
        "\n",
        "for i in range(num_channels):\n",
        "    feature = feature_map[0, i].detach().cpu().numpy()\n",
        "\n",
        "    # Normalize to [0, 255] for visualization\n",
        "    feature = (feature - feature.min()) / (feature.max() - feature.min())\n",
        "    feature = (feature * 255).astype('uint8')\n",
        "\n",
        "    img = Image.fromarray(feature)\n",
        "    save_path = os.path.join(save_dir, f'{layer_name}_{i+1}.png')\n",
        "    img.save(save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQ1F7zmzaLMk",
        "outputId": "d51b0107-e6f6-4ca1-cf2d-8d8a323dc274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 256, 120, 80])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> high freq"
      ],
      "metadata": {
        "id": "R7_NDk8sZ9OL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "layer_name = \"high-freq\"\n",
        "\n",
        "features = []\n",
        "def get_features(module, input, output):\n",
        "    features.append(output)\n",
        "\n",
        "layer = model.d3.c6\n",
        "hook = layer.register_forward_hook(get_features)\n",
        "\n",
        "output = model(image_tensor.to(device))\n",
        "\n",
        "feature_map = features[0]\n",
        "\n",
        "hook.remove()\n",
        "\n",
        "save_dir = f'../outputs/visualization/{layer_name}'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "batch_size, num_channels, height, width = feature_map.shape\n",
        "\n",
        "for i in range(num_channels):\n",
        "    feature = feature_map[0, i].detach().cpu().numpy()\n",
        "\n",
        "    # Normalize to [0, 255] for visualization\n",
        "    feature = (feature - feature.min()) / (feature.max() - feature.min())\n",
        "    feature = (feature * 255).astype('uint8')\n",
        "\n",
        "    img = Image.fromarray(feature)\n",
        "    save_path = os.path.join(save_dir, f'{layer_name}_{i+1}.png')\n",
        "    img.save(save_path)"
      ],
      "metadata": {
        "id": "KmctQMxoDNnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> low frequency"
      ],
      "metadata": {
        "id": "r5DeslK_ZL38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# low-freq\n",
        "layer_name = \"low-freq\"\n",
        "\n",
        "vgg3 = model.vgg_3.to(device)\n",
        "\n",
        "LR4x = F.interpolate(image_tensor, scale_factor=4, mode='bicubic')\n",
        "\n",
        "f = vgg3(LR4x.to(device))\n",
        "\n",
        "batch_size, num_channels, height, width = f.shape\n",
        "\n",
        "save_dir = f'../outputs/visualization/{layer_name}'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "batch_size, num_channels, height, width = feature_map.shape\n",
        "\n",
        "for i in range(num_channels):\n",
        "    feature = f[0, i].detach().cpu().numpy()\n",
        "\n",
        "    # Normalize to [0, 255] for visualization\n",
        "    feature = (feature - feature.min()) / (feature.max() - feature.min())\n",
        "    feature = (feature * 255).astype('uint8')\n",
        "\n",
        "    img = Image.fromarray(feature)\n",
        "    save_path = os.path.join(save_dir, f'{layer_name}_{i+11}.png')\n",
        "    img.save(save_path)"
      ],
      "metadata": {
        "id": "dXZhyF1iZvFA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "tzYd5tvnwp3e",
        "8OHhySgR7bxa",
        "dcVMqcmhGoY1",
        "G-mGy5ui3H6k"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}